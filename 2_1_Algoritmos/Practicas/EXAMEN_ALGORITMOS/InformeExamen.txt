---INFORME EXAMEN---

->EQUIPO
Camiña Caneda, Jaime	//	j.caneda@udc.es

->ESPECIFICACIONES DEL EQUIPO DONDE SE REALIZÓ LA PRÁCTICA

Chasis: Laptop
Sistema Operativo: Ubuntu 23.04
Kernel: Linux 6.2.0-39-generic
Arquitectura: x86_64
Modelo de CPU: 11th Gen Intel(R) Core(TM) i3-1115G4 @ 3.00GHz
RAM: 8 GB

->INTRODUCCIÓN A LA PRÁCTICA
	
	Fue realizada en el lenguaje de programación C. El objetivo es comprobar la complejidad de un algoritmo dado en la hoja de examen y comprobar su correcto funcionamiento de ordenación (Siendo esta de menor a mayor).
	Para ello usamos una función proporcionada por el profesorado que obtiene el tiempo en un momento determinado (En microsegundos) para luego compararlo con otro al acabar la ejecución del algoritmo a probar.
	Uno de los principales problemas eran los tiempos bajos, ya que tienden a ser más inexactos. Para ello usamos una condición que comprueba si t(n) es menor a 500 para repetir su medición con un valor K (Múltiplo de 10) = 1000. Explicados los fundamentos de la práctica, véase los tiempos obtenidos en el proceso.

->TIEMPOS

	!- Es importante recalcar que las filas de las tablas de tiempos que cuentan con  “(*)” son las que cumplieron la condición explicada anteriormente (t(n) < 500) y las señaladas con “¡AN!” son las que cuentan con anomalías. Además para las 3 situaciones de cada algoritmo, se obtiene una cota subestimada, estimada y sobrestimada. Para evitar las anomalías repetí los tiempos en numerosas ocasiones, escogiendo aquellas tablas que proporcionaban datos más exactos. Sin embargo, acabaron apareciendo una serie de anomalías, las cuales se deben, en su mayoría, a tiempos más elevados de lo esperado (Todos los casos están indicados). 

	Dentro del tema de la complejidad, en el mejor de los casos (inicialización aleatoria), la complejidad del algoritmo tiene una complejidad cercana a O(n). Sin embargo, ocurre algo bastante curioso cuando tratamos con vectores ordenados de forma descendente o ascendente, ya que los dos son cercanos a O(n^2). En el primer caso se puede deber por el pivote, que empezara siendo siempre el número 2, provocando un desbalanceo. En los vectores ascendentes ocurre de igual forma, ya que el primer pivote será siempre n-1, dando lugar al mismo efecto.

--Tiempos obtenidos---
Vector con inicializacion aleatoria

        n             t(n)    t(n)/n^0.900   t(n)/n^1.110  t(n)/n^1.300
(*)   500         31.56500    0.117525685    0.031867580    0.009784639
(*)  1000         68.80500    0.137284024    0.032182516    0.008662036
(*)  2000        150.26000    0.160663191    0.032561177    0.007682532
(*)  4000        324.27400    0.185805317    0.032555588    0.006733396
     8000        702.00000    0.215554019    0.032651807    0.005919978
    16000       1482.00000    0.243859803    0.031935596    0.005075657
    32000       3164.00000    0.278998260    0.031587845    0.004400900
    64000       6757.00000    0.319294871    0.031253175    0.003816981
			     [Subestimada]    [Estimada]  [Sobreestimada]	
				
Cota subestimada -> n^0.9  -> Tiende a infinito
Cota estimada      -> n^1.11   -> Tiende a 0.032
Cota sobrestimada -> n^1.3   -> Tiende a 0

Vector con inicializacion ascendente        
	n             t(n)   t(n)/n^1.800   t(n)/n^2.000   t(n)/n^2.200
(*)   500        135.07000    0.001872461    0.000540280    0.000155892  --> ¡AN!
     1000        525.00000    0.002090063    0.000525000    0.000131874
     2000       2076.00000    0.002373413    0.000519000    0.000113491
     4000       8231.00000    0.002702369    0.000514438    0.000097931
     8000      33281.00000    0.003137866    0.000520016    0.000086178
    16000     131809.00000    0.003568857    0.000514879    0.000074282
    32000     526420.00000    0.004093195    0.000514082    0.000064566
    64000    2104960.00000    0.004700238    0.000513906    0.000056189
			     [Subestimada]    [Estimada]  [Sobreestimada]

Cota subestimada -> n^1.8   -> Tiende a infinito
Cota estimada      -> n^2.0    -> Tiende a 0.00052
Cota sobrestimada -> n^2.2    -> Tiende a 0

Vector con inicializacion descendente
        n             t(n)   t(n)/n^1.800   t(n)/n^1.990   t(n)/n^2.200
(*)   500        254.02800    0.003521564    0.001081263    0.000293189
     1000        983.00000    0.003913393    0.001053303    0.000246918
     2000       3904.00000    0.004463297    0.001053077    0.000213424
     4000      15572.00000    0.005112536    0.001057414    0.000185273
     8000      61751.00000    0.005822132    0.001055589    0.000159899
    16000     245963.00000    0.006659687    0.001058452    0.000138614
    32000     987489.00000    0.007678251    0.001069754    0.000121116
    64000    3967513.00000    0.008859198    0.001081982    0.000105906
			     [Subestimada]    [Estimada]  [Sobreestimada]
				
Cota subestimada -> n^1.8   -> Tiende a infinito
Cota estimada      -> n^2       -> Tiende a 0.00106
Cota sobrestimada -> n^2.2    -> Tiende a 0

->CONCLUSIÓN

	Este algoritmo tiene un comportamiento muy parecido a "Quicksort". Los tiempos y las complejidades obtenidas confirman esta afirmación, ya que su comportamiento es el esperado por dicho algoritmo. Dentro de la complejidad podemos decir que cuanto más aleatorio sea el vector introducido mejores tiempos nos dará, puesto que cuando ya viene ordenado tanto de forma ascendente como descendente este tiende a obtener mayores tiempos.
	
	En general, si contamos con un método de asegurar que los vectores que se le introduzcan son considerablemente aleatorios, el algoritmo puede ser considerablemente eficiente si buscamos uno rápido al ordenar. 




